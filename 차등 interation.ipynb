{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef0edf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup cell is ready.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. 환경 설정 셀 (수정된 버전) ---\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# 작업 디렉토리를 올바른 위치로 변경\n",
    "workspace_path = '/workspace'\n",
    "os.chdir(workspace_path)\n",
    "\n",
    "# RFdiffusion 경로를 파이썬이 인식하도록 추가\n",
    "rfdiffusion_path = os.path.join(workspace_path, 'RFdiffusion')\n",
    "if rfdiffusion_path not in sys.path:\n",
    "    sys.path.append(rfdiffusion_path)\n",
    "import time\n",
    "import signal\n",
    "import sys\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "import py3Dmol\n",
    "\n",
    "# Colab이 아닌 로컬 환경이므로, RFdiffusion 경로를 직접 추가\n",
    "if 'RFdiffusion' not in sys.path:\n",
    "    home_dir = os.path.expanduser(\"~\")\n",
    "    rfdiffusion_path = os.path.join(home_dir, 'RFdiffusion')\n",
    "    sys.path.append(rfdiffusion_path)\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "\n",
    "from inference.utils import parse_pdb\n",
    "from colabdesign.rf.utils import get_ca\n",
    "from colabdesign.rf.utils import fix_contigs, fix_partial_contigs, fix_pdb, sym_it\n",
    "from colabdesign.shared.protein import pdb_to_string\n",
    "from colabdesign.shared.plot import plot_pseudo_3D\n",
    "\n",
    "# --- Colab의 files.upload()를 대체하는 로컬 파일 처리 함수 ---\n",
    "def get_pdb(pdb_code=None, use_upload=False):\n",
    "    if use_upload:\n",
    "        upload_widget = widgets.FileUpload(\n",
    "            accept='.pdb', description='PDB 파일 업로드', button_style='info'\n",
    "        )\n",
    "        display(upload_widget)\n",
    "        \n",
    "        def wait_for_upload(widget):\n",
    "            while len(widget.value) == 0: time.sleep(0.1)\n",
    "            uploaded_filename = list(widget.value.keys())[0]\n",
    "            pdb_content = widget.value[uploaded_filename]['content']\n",
    "            pdb_filename = \"tmp.pdb\"\n",
    "            with open(pdb_filename, \"wb\") as out: out.write(pdb_content)\n",
    "            print(f\"'{uploaded_filename}'이(가) 'tmp.pdb'로 저장되었습니다.\")\n",
    "            return pdb_filename\n",
    "            \n",
    "        return wait_for_upload(upload_widget)\n",
    "    elif pdb_code is None or pdb_code == \"\":\n",
    "        print(\"PDB 코드를 입력하거나 use_upload=True로 설정하세요.\")\n",
    "        return None\n",
    "    elif os.path.isfile(pdb_code): return pdb_code\n",
    "    elif len(pdb_code) == 4:\n",
    "        pdb_filename = f\"{pdb_code}.pdb1\"\n",
    "        if not os.path.isfile(pdb_filename):\n",
    "            os.system(f\"wget -qnc https://files.rcsb.org/download/{pdb_code}.pdb1.gz && gunzip -f {pdb_code}.pdb1.gz\")\n",
    "        return pdb_filename\n",
    "    else:\n",
    "        pdb_filename = f\"AF-{pdb_code}-F1-model_v4.pdb\"\n",
    "        if not os.path.isfile(pdb_filename):\n",
    "            os.system(f\"wget -qnc https://alphafold.ebi.ac.uk/files/{pdb_filename}\")\n",
    "        return pdb_filename\n",
    "\n",
    "def run_ananas(pdb_str, path, sym=None):\n",
    "    pdb_filename = f\"outputs/{path}/ananas_input.pdb\"\n",
    "    out_filename = f\"outputs/{path}/ananas.json\"\n",
    "    os.makedirs(f\"outputs/{path}\", exist_ok=True)\n",
    "    with open(pdb_filename,\"w\") as handle: handle.write(pdb_str)\n",
    "    cmd = f\"./ananas {pdb_filename} -u -j {out_filename}\"\n",
    "    if sym is None: os.system(cmd)\n",
    "    else: os.system(f\"{cmd} {sym}\")\n",
    "    try:\n",
    "        with open(out_filename,\"r\") as f: out = json.load(f)\n",
    "        results, AU = out[0], out[-1][\"AU\"]\n",
    "        group, chains, rmsd = AU[\"group\"], AU[\"chain names\"], results[\"Average_RMSD\"]\n",
    "        print(f\"AnAnaS detected {group} symmetry at RMSD:{rmsd:.3}\")\n",
    "        C = np.array(results['transforms'][0]['CENTER'])\n",
    "        A = [np.array(t[\"AXIS\"]) for t in results['transforms']]\n",
    "        new_lines = []\n",
    "        for line in pdb_str.split(\"\\n\"):\n",
    "            if line.startswith(\"ATOM\"):\n",
    "                chain = line[21:22]\n",
    "                if chain in chains:\n",
    "                    x = np.array([float(line[i:(i+8)]) for i in [30,38,46]])\n",
    "                    if group[0] == \"c\": x = sym_it(x,C,A[0])\n",
    "                    if group[0] == \"d\": x = sym_it(x,C,A[1],A[0])\n",
    "                    coord_str = \"\".join([f\"{a:8.3f}\" for a in x])\n",
    "                    new_lines.append(line[:30]+coord_str+line[54:])\n",
    "            else: new_lines.append(line)\n",
    "        return results, \"\\n\".join(new_lines)\n",
    "    except Exception as e:\n",
    "        print(f\"AnAnaS 결과 처리 중 오류 발생: {e}\")\n",
    "        return None, pdb_str\n",
    "\n",
    "def run(command, steps, num_designs=1, visual=\"none\"):\n",
    "    def run_command_and_get_pid(command):\n",
    "        pid_file = '/dev/shm/pid'\n",
    "        os.system(f'nohup {command} > /dev/null & echo $! > {pid_file}')\n",
    "        with open(pid_file, 'r') as f: pid = int(f.read().strip())\n",
    "        os.remove(pid_file)\n",
    "        return pid\n",
    "    def is_process_running(pid):\n",
    "        try: os.kill(pid, 0)\n",
    "        except OSError: return False\n",
    "        else: return True\n",
    "    run_output = widgets.Output()\n",
    "    progress = widgets.FloatProgress(min=0, max=1, description='running', bar_style='info')\n",
    "    display(widgets.VBox([progress, run_output]))\n",
    "    for n in range(steps):\n",
    "        if os.path.isfile(f\"/dev/shm/{n}.pdb\"): os.remove(f\"/dev/shm/{n}.pdb\")\n",
    "    pid = run_command_and_get_pid(command)\n",
    "    try:\n",
    "        fail = False\n",
    "        for _ in range(num_designs):\n",
    "            for n in range(steps):\n",
    "                wait = True\n",
    "                while wait and not fail:\n",
    "                    time.sleep(0.1)\n",
    "                    if os.path.isfile(f\"/dev/shm/{n}.pdb\"):\n",
    "                        with open(f\"/dev/shm/{n}.pdb\", \"r\") as f: pdb_str = f.read()\n",
    "                        if \"TER\" in pdb_str or \"ENDMDL\" in pdb_str: wait = False\n",
    "                        elif not is_process_running(pid): fail = True\n",
    "                    elif not is_process_running(pid): fail = True\n",
    "                if fail:\n",
    "                    progress.bar_style = 'danger'; progress.description = \"failed\"\n",
    "                    break\n",
    "                else:\n",
    "                    progress.value = (n+1) / steps\n",
    "                    if visual != \"none\":\n",
    "                        with run_output:\n",
    "                            run_output.clear_output(wait=True)\n",
    "                            if visual == \"image\":\n",
    "                                xyz, bfact = get_ca(f\"/dev/shm/{n}.pdb\", get_bfact=True)\n",
    "                                fig = plt.figure(); fig.set_dpi(100);fig.set_figwidth(6);fig.set_figheight(6)\n",
    "                                ax1 = fig.add_subplot(111);ax1.set_xticks([]);ax1.set_yticks([])\n",
    "                                plot_pseudo_3D(xyz, c=bfact, cmin=0.5, cmax=0.9, ax=ax1); plt.show()\n",
    "                            if visual == \"interactive\":\n",
    "                                view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js')\n",
    "                                view.addModel(pdb_str,'pdb'); view.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':0.5,'max':0.9}}})\n",
    "                                view.zoomTo(); view.show()\n",
    "                if os.path.exists(f\"/dev/shm/{n}.pdb\"): os.remove(f\"/dev/shm/{n}.pdb\")\n",
    "            if fail:\n",
    "                progress.bar_style = 'danger'; progress.description = \"failed\"\n",
    "                break\n",
    "        while is_process_running(pid): time.sleep(0.1)\n",
    "    except KeyboardInterrupt:\n",
    "        os.kill(pid, signal.SIGTERM); progress.bar_style = 'danger'; progress.description = \"stopped\"\n",
    "    \n",
    "def run_diffusion(contigs, path, pdb=None, iterations=50, symmetry=\"none\", order=1, hotspot=None,\n",
    "                  chains=None, add_potential=False, num_designs=1, visual=\"none\"):\n",
    "    full_path = f\"outputs/{path}\"; os.makedirs(full_path, exist_ok=True)\n",
    "    opts = [f\"inference.output_prefix={full_path}\", f\"inference.num_designs={num_designs}\"]\n",
    "    if chains == \"\": chains = None\n",
    "    if symmetry in [\"auto\",\"cyclic\",\"dihedral\"]:\n",
    "        if symmetry == \"auto\": sym, copies = None, 1\n",
    "        else: sym, copies = {\"cyclic\":(f\"c{order}\",order), \"dihedral\":(f\"d{order}\",order*2)}[symmetry]\n",
    "    else: symmetry = None; sym, copies = None, 1\n",
    "    contigs_list = contigs.replace(\",\",\" \").replace(\":\",\" \").split()\n",
    "    is_fixed, is_free = False, False; fixed_chains = []\n",
    "    for contig in contigs_list:\n",
    "        for x in contig.split(\"/\"):\n",
    "            a = x.split(\"-\")[0]\n",
    "            if a and a[0].isalpha():\n",
    "                is_fixed = True\n",
    "                if a[0] not in fixed_chains: fixed_chains.append(a[0])\n",
    "            if a.isnumeric(): is_free = True\n",
    "    if len(contigs_list) == 0 or not is_free: mode = \"partial\"\n",
    "    elif is_fixed: mode = \"fixed\"\n",
    "    else: mode = \"free\"\n",
    "    if mode in [\"partial\",\"fixed\"]:\n",
    "        pdb_str = pdb_to_string(pdb, chains=chains)\n",
    "        if symmetry == \"auto\":\n",
    "            a, pdb_str = run_ananas(pdb_str, path)\n",
    "            if a is None: print(f'ERROR: no symmetry detected'); symmetry = None; sym, copies = None, 1\n",
    "            else:\n",
    "                if a[\"group\"][0] == \"c\": symmetry = \"cyclic\"; sym, copies = a[\"group\"], int(a[\"group\"][1:])\n",
    "                elif a[\"group\"][0] == \"d\": symmetry = \"dihedral\"; sym, copies = a[\"group\"], 2 * int(a[\"group\"][1:])\n",
    "                else: print(f'ERROR: detected symm ({a[\"group\"]}) not supported'); symmetry = None; sym, copies = None, 1\n",
    "        elif mode == \"fixed\": pdb_str = pdb_to_string(pdb_str, chains=fixed_chains)\n",
    "        pdb_filename = f\"{full_path}/input.pdb\"\n",
    "        with open(pdb_filename, \"w\") as handle: handle.write(pdb_str)\n",
    "        parsed_pdb = parse_pdb(pdb_filename)\n",
    "        opts.append(f\"inference.input_pdb={pdb_filename}\")\n",
    "        if mode in [\"partial\"]:\n",
    "            iterations = int(80 * (iterations / 200)); opts.append(f\"diffuser.partial_T={iterations}\")\n",
    "            contigs_list = fix_partial_contigs(contigs_list, parsed_pdb)\n",
    "        else: opts.append(f\"diffuser.T={iterations}\"); contigs_list = fix_contigs(contigs_list, parsed_pdb)\n",
    "    else:\n",
    "        opts.append(f\"diffuser.T={iterations}\"); parsed_pdb = None\n",
    "        contigs_list = fix_contigs(contigs_list, parsed_pdb)\n",
    "    if hotspot is not None and hotspot != \"\": opts.append(f\"ppi.hotspot_res=[{hotspot}]\")\n",
    "    if sym is not None:\n",
    "        sym_opts = [\"--config-name symmetry\", f\"inference.symmetry={sym}\"]\n",
    "        if add_potential: sym_opts += [\"'potentials.guiding_potentials=[\\\"type:olig_contacts,weight_intra:1,weight_inter:0.1\\\"]'\", \"potentials.olig_intra_all=True\",\"potentials.olig_inter_all=True\", \"potentials.guide_scale=2\",\"potentials.guide_decay=quadratic\"]\n",
    "        opts = sym_opts + opts; contigs_list = sum([contigs_list] * copies,[])\n",
    "    opts.append(f\"'contigmap.contigs=[{' '.join(contigs_list)}]'\")\n",
    "    opts += [\"inference.dump_pdb=True\",\"inference.dump_pdb_path='/dev/shm'\"]\n",
    "    print(\"mode:\", mode); print(\"output:\", full_path); print(\"contigs:\", contigs_list)\n",
    "    run_script_path = \"/workspace/RFdiffusion/run_inference.py\"\n",
    "    opts_str = \" \".join(opts)\n",
    "    cmd = f\"python {run_script_path} {opts_str}\"\n",
    "    print(cmd)\n",
    "    run(cmd, iterations, num_designs, visual=visual)\n",
    "    for n in range(num_designs):\n",
    "        pdbs = [f\"outputs/traj/{path}_{n}_pX0_traj.pdb\", f\"outputs/traj/{path}_{n}_Xt-1_traj.pdb\", f\"{full_path}_{n}.pdb\"]\n",
    "        for pdb_file in pdbs:\n",
    "            if os.path.exists(pdb_file):\n",
    "                with open(pdb_file,\"r\") as handle: pdb_str = handle.read()\n",
    "                with open(pdb_file,\"w\") as handle: handle.write(fix_pdb(pdb_str, contigs_list))\n",
    "    return contigs_list, copies\n",
    "\n",
    "print(\"✅ Setup cell is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac30d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [단계 1] 백본이 저장될 기본 폴더: outputs/0821-binder-backbones\n",
      "🚀 RFdiffusion으로 백본 생성을 시작합니다 (간격: 50, 최종: 500).\n",
      "\n",
      "==================================================\n",
      "▶️ 현재 Iteration 단계 실행: 50\n",
      "   - 저장 경로: outputs/0821-binder-backbones/iter_50/design_iter_50_0.pdb ...\n",
      "mode: fixed\n",
      "output: outputs/0821-binder-backbones/iter_50/design_iter_50\n",
      "contigs: ['C311-391', '100-100']\n",
      "python /workspace/RFdiffusion/run_inference.py inference.output_prefix=outputs/0821-binder-backbones/iter_50/design_iter_50 inference.num_designs=50 inference.input_pdb=outputs/0821-binder-backbones/iter_50/design_iter_50/input.pdb diffuser.T=50 ppi.hotspot_res=[C331,C360,C378,C381,C323] 'contigmap.contigs=[C311-391 100-100]' inference.dump_pdb=True inference.dump_pdb_path='/dev/shm'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd6d7d61b7043a6a4ec76cfdf4168f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatProgress(value=0.0, bar_style='info', description='running', max=1.0), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "▶️ 현재 Iteration 단계 실행: 100\n",
      "   - 저장 경로: outputs/0821-binder-backbones/iter_100/design_iter_100_0.pdb ...\n",
      "mode: fixed\n",
      "output: outputs/0821-binder-backbones/iter_100/design_iter_100\n",
      "contigs: ['C311-391', '100-100']\n",
      "python /workspace/RFdiffusion/run_inference.py inference.output_prefix=outputs/0821-binder-backbones/iter_100/design_iter_100 inference.num_designs=50 inference.input_pdb=outputs/0821-binder-backbones/iter_100/design_iter_100/input.pdb diffuser.T=100 ppi.hotspot_res=[C331,C360,C378,C381,C323] 'contigmap.contigs=[C311-391 100-100]' inference.dump_pdb=True inference.dump_pdb_path='/dev/shm'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb25f9d4d98748d0b6e81300d160f963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatProgress(value=0.0, bar_style='info', description='running', max=1.0), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 필요한 라이브러리 import ---\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "# --- 바인더 디자인 실행 셀 (1단계: 백본 생성) ---\n",
    "\n",
    "# 1. 파라미터 설정\n",
    "# -----------------------------------------------------------------\n",
    "name = \"0821-binder-backbones\"\n",
    "contigs = \"C311-391/0 100-100\"\n",
    "hotspot = \"C331,C360,C378,C381,C323\"\n",
    "num_designs = 50  # 예시로 개수를 줄임 (필요시 200으로 다시 조절)\n",
    "pdb_filename = \"4k9e_c.pdb\"\n",
    "\n",
    "# --- 중간 저장 파라미터 ---\n",
    "total_iterations = 500\n",
    "save_interval = 50\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "\n",
    "# 2. PDB 파일 경로 및 기본 출력 폴더 설정\n",
    "pdb = os.path.join(\"/workspace\", pdb_filename)\n",
    "base_name = name\n",
    "output_dir = f\"outputs/{base_name}\"\n",
    "\n",
    "# 중복 방지 폴더명 생성\n",
    "while os.path.exists(output_dir):\n",
    "    random_suffix = ''.join(random.choices(string.ascii_lowercase + string.digits, k=5))\n",
    "    base_name = f\"{name}_{random_suffix}\"\n",
    "    output_dir = f\"outputs/{base_name}\"\n",
    "\n",
    "print(f\"✅ [단계 1] 백본이 저장될 기본 폴더: {output_dir}\")\n",
    "\n",
    "\n",
    "# 3. RFdiffusion 반복 실행\n",
    "# -----------------------------------------------------------------\n",
    "print(f\"🚀 RFdiffusion으로 백본 생성을 시작합니다 (간격: {save_interval}, 최종: {total_iterations}).\")\n",
    "\n",
    "for current_iter in range(save_interval, total_iterations + 1, save_interval):\n",
    "    print(f\"\\n{'='*50}\\n▶️ 현재 Iteration 단계 실행: {current_iter}\")\n",
    "    \n",
    "    iter_folder_name = f\"iter_{current_iter}\"\n",
    "    iter_file_prefix = f\"design_iter_{current_iter}\"\n",
    "    path = os.path.join(base_name, iter_folder_name, iter_file_prefix)\n",
    "\n",
    "    print(f\"   - 저장 경로: outputs/{path}_0.pdb ...\")\n",
    "\n",
    "    flags = {\n",
    "        \"contigs\": contigs, \"pdb\": pdb, \"iterations\": int(current_iter),\n",
    "        \"hotspot\": hotspot, \"path\": path, \"num_designs\": int(num_designs),\n",
    "        \"visual\": \"none\", \"symmetry\": \"none\", \"order\": 1, \"chains\": \"\",\n",
    "        \"add_potential\": True\n",
    "    }\n",
    "\n",
    "    for k, v in flags.items():\n",
    "        if isinstance(v, str):\n",
    "            flags[k] = v.replace(\"'\", \"\").replace('\"', '')\n",
    "    \n",
    "    run_diffusion(**flags) # 이 함수가 실행된다고 가정\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"✅ [단계 1] 백본 생성 완료! 결과는 '{output_dir}' 폴더에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedbddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 필요한 라이브러리 import ---\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# --- 디자인 및 예측 실행 셀 (2단계: 서열 디자인 및 검증) ---\n",
    "\n",
    "# 1. 파라미터 설정\n",
    "# -----------------------------------------------------------------\n",
    "# 단계 1에서 결과가 저장된 기본 폴더 경로를 정확하게 입력합니다.\n",
    "# 위 코드에서 `output_dir`로 출력된 최종 폴더명을 사용하세요.\n",
    "rfdiffusion_results_dir = \"outputs/0821-binder-backbones\" # ⚠️ 여기를 확인하고 수정하세요!\n",
    "\n",
    "# ProteinMPNN과 ColabFold(ColabDesign) 실행 스크립트 또는 명령어 경로\n",
    "# 실제 환경에 맞게 수정해야 합니다.\n",
    "protein_mpnn_script = \"/path/to/ProteinMPNN/protein_mpnn_run.py\"\n",
    "colabfold_command = \"colabfold_batch\" # colabfold가 환경에 설치되어 있다고 가정\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "print(f\"✅ [단계 2] 서열 디자인 및 구조 예측을 시작합니다.\")\n",
    "print(f\"   - 대상 폴더: {rfdiffusion_results_dir}\")\n",
    "\n",
    "# 2. 모든 PDB 파일을 순회하며 작업 실행\n",
    "if not os.path.isdir(rfdiffusion_results_dir):\n",
    "    print(f\"⚠️ 에러: '{rfdiffusion_results_dir}' 폴더를 찾을 수 없습니다. 경로를 확인해주세요.\")\n",
    "else:\n",
    "    # os.walk를 사용하여 모든 하위 폴더를 탐색\n",
    "    for root, dirs, files in os.walk(rfdiffusion_results_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdb\"):\n",
    "                pdb_path = os.path.join(root, file)\n",
    "                \n",
    "                print(f\"\\n{'--'*25}\\n▶️ 처리 중인 파일: {pdb_path}\")\n",
    "\n",
    "                # --- 🧬 ProteinMPNN 실행 ---\n",
    "                # 결과가 저장될 경로 설정 (PDB 파일과 같은 폴더에 저장)\n",
    "                mpnn_output_path = os.path.join(root, \"mpnn_outputs\")\n",
    "                os.makedirs(mpnn_output_path, exist_ok=True)\n",
    "                \n",
    "                mpnn_command = [\n",
    "                    \"python\", protein_mpnn_script,\n",
    "                    \"--pdb_path\", pdb_path,\n",
    "                    \"--out_folder\", mpnn_output_path,\n",
    "                    \"--num_seq_per_target\", \"1\", # 백본 당 1개의 서열 생성 (필요시 조절)\n",
    "                    \"--sampling_temp\", \"0.1\"\n",
    "                ]\n",
    "                \n",
    "                print(f\"   - (1/2) ProteinMPNN으로 서열 디자인 실행...\")\n",
    "                # subprocess.run(mpnn_command, capture_output=True, text=True) # 실제 실행 시 주석 해제\n",
    "\n",
    "                # --- 🤖 ColabDesign (ColabFold) 실행 ---\n",
    "                # ProteinMPNN 결과(FASTA 파일)를 입력으로 사용\n",
    "                # 실제 파일 이름은 ProteinMPNN 출력 형식에 맞게 수정 필요\n",
    "                base_name = os.path.splitext(file)[0]\n",
    "                fasta_path = os.path.join(mpnn_output_path, \"seqs\", f\"{base_name}.fa\")\n",
    "                \n",
    "                colabdesign_output_path = os.path.join(root, \"colabdesign_outputs\")\n",
    "                # os.makedirs(colabdesign_output_path, exist_ok=True) # colabfold_batch가 자동으로 폴더 생성\n",
    "\n",
    "                # if os.path.exists(fasta_path): # 실제 실행 시 주석 해제\n",
    "                colabfold_run_command = [\n",
    "                    colabfold_command,\n",
    "                    fasta_path, # ProteinMPNN이 생성한 fasta 파일\n",
    "                    colabdesign_output_path\n",
    "                ]\n",
    "                \n",
    "                print(f\"   - (2/2) ColabDesign으로 구조 예측 및 검증 실행...\")\n",
    "                # subprocess.run(colabfold_run_command, capture_output=True, text=True) # 실제 실행 시 주석 해제\n",
    "                # else: # 실제 실행 시 주석 해제\n",
    "                #    print(f\"   - ⚠️ 경고: ProteinMPNN의 결과 파일({fasta_path})을 찾을 수 없어 ColabDesign을 건너뜁니다.\")\n",
    "\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"✅ [단계 2] 모든 백본에 대한 서열 디자인 및 구조 예측 작업이 완료되었습니다.\")\n",
    "print(\"📊 이제 각 colabdesign_outputs 폴더에 있는 pLDDT, RMSD 등의 점수를 확인하여 최고의 디자인을 선별하세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2bc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmsd & i_pae 조정해서 디자인 선별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893e8d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'outputs/0819-50-200/0819-50-200/mpnn_results.csv' 파일에서 결과 분석을 시작합니다.\n",
      "✅ 적용할 필터링 조건: rmsd < 3.0 AND i_pae < 15.0\n",
      "\n",
      "📊 총 9개의 디자인이 설정된 조건을 만족했습니다.\n",
      "🔬 총 4개의 Backbone에서 디자인이 선별되었습니다.\n",
      "\n",
      "Backbone별 통과된 디자인 개수 (많은 순):\n",
      "  - Backbone 'design33': 5개 통과\n",
      "  - Backbone 'design147': 2개 통과\n",
      "  - Backbone 'design106': 1개 통과\n",
      "  - Backbone 'design130': 1개 통과\n",
      "\n",
      "📋 선별된 디자인 전체 목록 (RMSD 오름차순):\n",
      " Unnamed: 0  design    plddt     i_pae     rmsd\n",
      "        268      33 0.912716  8.088408 1.670351\n",
      "        270      33 0.926660  7.647270 1.776981\n",
      "        269      33 0.922526  8.518820 1.920088\n",
      "        264      33 0.921417  8.165914 2.084753\n",
      "       1176     147 0.916483 10.029659 2.174413\n",
      "        265      33 0.924587  8.333292 2.207138\n",
      "        849     106 0.932891 12.802895 2.514534\n",
      "       1183     147 0.809654 13.867611 2.551431\n",
      "       1045     130 0.819364  9.935198 2.893448\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 분석할 파일 경로와 필터링 조건 설정\n",
    "results_csv_path = \"outputs/0819-50-200/0819-50-200/mpnn_results.csv\"\n",
    "RMSD_THRESHOLD = 3.0\n",
    "IPAE_THRESHOLD = 15.0\n",
    "\n",
    "print(f\"'{results_csv_path}' 파일에서 결과 분석을 시작합니다.\")\n",
    "print(f\"✅ 적용할 필터링 조건: rmsd < {RMSD_THRESHOLD} AND i_pae < {IPAE_THRESHOLD}\")\n",
    "\n",
    "# 2. CSV 파일 읽기\n",
    "try:\n",
    "    df_all = pd.read_csv(results_csv_path)\n",
    "    \n",
    "    # 3. 설정된 조건으로 데이터 필터링\n",
    "    df_filtered = df_all[(df_all['rmsd'] < RMSD_THRESHOLD) & (df_all['i_pae'] < IPAE_THRESHOLD)].copy()\n",
    "    \n",
    "    print(f\"\\n📊 총 {len(df_filtered)}개의 디자인이 설정된 조건을 만족했습니다.\")\n",
    "\n",
    "    # 4. 필터링된 결과가 있으면 요약 및 목록 출력\n",
    "    if not df_filtered.empty:\n",
    "        backbone_counts = df_filtered['design'].value_counts()\n",
    "        \n",
    "        # ⭐️⭐️⭐️ 요청하신 추가 부분 ⭐️⭐️⭐️\n",
    "        print(f\"🔬 총 {len(backbone_counts)}개의 Backbone에서 디자인이 선별되었습니다.\")\n",
    "        \n",
    "        # Backbone별 통과된 디자인 개수 요약 (내림차순)\n",
    "        print(\"\\nBackbone별 통과된 디자인 개수 (많은 순):\")\n",
    "        for design_id, count in backbone_counts.items():\n",
    "            print(f\"  - Backbone 'design{design_id}': {count}개 통과\")\n",
    "        \n",
    "        # RMSD 기준으로 오름차순 정렬\n",
    "        df_sorted = df_filtered.sort_values(by='rmsd', ascending=True)\n",
    "        \n",
    "        # 최종 선별된 디자인 목록 전체 출력\n",
    "        print(\"\\n📋 선별된 디자인 전체 목록 (RMSD 오름차순):\")\n",
    "        print(df_sorted[['Unnamed: 0', 'design', 'plddt', 'i_pae', 'rmsd']].to_string(index=False))\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n조건을 만족하는 디자인이 없습니다.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n🚨 에러: 결과 파일({results_csv_path})을 찾을 수 없습니다. 파일 경로를 확인해주세요.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
